{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T06:50:33.734359Z",
     "iopub.status.busy": "2024-05-30T06:50:33.733823Z",
     "iopub.status.idle": "2024-05-30T06:50:49.712474Z",
     "shell.execute_reply": "2024-05-30T06:50:49.711361Z",
     "shell.execute_reply.started": "2024-05-30T06:50:33.734317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.29.3)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-0.30.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: accelerate\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.29.3\n",
      "    Uninstalling accelerate-0.29.3:\n",
      "      Successfully uninstalled accelerate-0.29.3\n",
      "Successfully installed accelerate-0.30.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T06:51:13.228206Z",
     "iopub.status.busy": "2024-05-30T06:51:13.227508Z",
     "iopub.status.idle": "2024-05-30T06:51:25.476976Z",
     "shell.execute_reply": "2024-05-30T06:51:25.476031Z",
     "shell.execute_reply.started": "2024-05-30T06:51:13.228172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in /opt/conda/lib/python3.10/site-packages (4.39.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (4.66.1)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.1.2)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.30.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers[torch]) (3.1.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->transformers[torch]) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T06:51:26.695300Z",
     "iopub.status.busy": "2024-05-30T06:51:26.694523Z",
     "iopub.status.idle": "2024-05-30T06:51:54.565141Z",
     "shell.execute_reply": "2024-05-30T06:51:54.564371Z",
     "shell.execute_reply.started": "2024-05-30T06:51:26.695265Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-30 06:51:42.358018: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-30 06:51:42.358119: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-30 06:51:42.618777: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import BartTokenizer\n",
    "import torch\n",
    "from transformers import BartForConditionalGeneration, Trainer, TrainingArguments\n",
    "from accelerate import Accelerator, DataLoaderConfiguration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T06:51:56.321489Z",
     "iopub.status.busy": "2024-05-30T06:51:56.320527Z",
     "iopub.status.idle": "2024-05-30T06:51:56.374321Z",
     "shell.execute_reply": "2024-05-30T06:51:56.373360Z",
     "shell.execute_reply.started": "2024-05-30T06:51:56.321453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  print(\"CUDA is available!\")\n",
    "else:\n",
    "  print(\"CUDA is not available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T06:51:57.209224Z",
     "iopub.status.busy": "2024-05-30T06:51:57.208779Z",
     "iopub.status.idle": "2024-05-30T06:51:57.323206Z",
     "shell.execute_reply": "2024-05-30T06:51:57.322387Z",
     "shell.execute_reply.started": "2024-05-30T06:51:57.209197Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load your data\n",
    "data = pd.read_csv('/kaggle/input/data-train/data_train.csv', header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T06:51:58.345806Z",
     "iopub.status.busy": "2024-05-30T06:51:58.345188Z",
     "iopub.status.idle": "2024-05-30T06:51:58.410079Z",
     "shell.execute_reply": "2024-05-30T06:51:58.409384Z",
     "shell.execute_reply.started": "2024-05-30T06:51:58.345776Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data\n",
    "# Create empty lists to store reactants and products\n",
    "reactants = []\n",
    "products = []\n",
    "\n",
    "# Iterate through each row in column one (assuming SMILES strings are there)\n",
    "for row in data.iloc[:, 0]:  # Access all rows in column 0 (index 0)\n",
    "    if pd.isna(row):  # Skip rows with missing values (NaN)\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # Split the SMILES string based on \">>\" (assuming one product)\n",
    "        split_data = row.split('>>')\n",
    "\n",
    "        # Extract reactants\n",
    "        reactants.append(split_data[0].strip())  # Remove leading/trailing whitespace\n",
    "\n",
    "        # Extract product\n",
    "        products.append(split_data[1].strip())  # Remove leading/trailing whitespace\n",
    "    except IndexError:  # Handle cases where there's no \">>\" separator\n",
    "        reactants.append(row.strip())  # Assume the entire row is a single reactant\n",
    "\n",
    "# Create a new DataFrame\n",
    "df = pd.DataFrame({'Reactant': reactants, 'Product': products})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T06:51:58.948231Z",
     "iopub.status.busy": "2024-05-30T06:51:58.947891Z",
     "iopub.status.idle": "2024-05-30T06:51:58.961503Z",
     "shell.execute_reply": "2024-05-30T06:51:58.960523Z",
     "shell.execute_reply.started": "2024-05-30T06:51:58.948204Z"
    }
   },
   "outputs": [],
   "source": [
    "reactants = df['Reactant']\n",
    "products = df['Product']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T06:52:00.249541Z",
     "iopub.status.busy": "2024-05-30T06:52:00.248596Z",
     "iopub.status.idle": "2024-05-30T06:52:00.253279Z",
     "shell.execute_reply": "2024-05-30T06:52:00.252398Z",
     "shell.execute_reply.started": "2024-05-30T06:52:00.249508Z"
    }
   },
   "outputs": [],
   "source": [
    "# Swap the input and target data\n",
    "input_data = products\n",
    "target_data = reactants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T06:52:01.947760Z",
     "iopub.status.busy": "2024-05-30T06:52:01.947145Z",
     "iopub.status.idle": "2024-05-30T06:52:03.022305Z",
     "shell.execute_reply": "2024-05-30T06:52:03.021498Z",
     "shell.execute_reply.started": "2024-05-30T06:52:01.947727Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0503cb7d85cd4e49a2fe15c15e407d58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c5aa3d49d084103b0bbd5f40a5c98af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18fb9b2e365d47c09c6d610668f3d79c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc60eb75e48a4e5895e90a2dd81b6ab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6577f45f3c43b5af50e19b781b39a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the tokenizer Bart\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T06:52:05.679013Z",
     "iopub.status.busy": "2024-05-30T06:52:05.678203Z",
     "iopub.status.idle": "2024-05-30T06:52:20.186081Z",
     "shell.execute_reply": "2024-05-30T06:52:20.185050Z",
     "shell.execute_reply.started": "2024-05-30T06:52:05.678981Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenize the new input and target data\n",
    "input_encodings = tokenizer(input_data.tolist(), truncation=True, padding=True, max_length=512)\n",
    "target_encodings = tokenizer(target_data.tolist(), truncation=True, padding=True, max_length=512)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T06:52:21.830908Z",
     "iopub.status.busy": "2024-05-30T06:52:21.830126Z",
     "iopub.status.idle": "2024-05-30T06:52:21.837198Z",
     "shell.execute_reply": "2024-05-30T06:52:21.836273Z",
     "shell.execute_reply.started": "2024-05-30T06:52:21.830877Z"
    }
   },
   "outputs": [],
   "source": [
    "class ChemicalDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, input_encodings, target_encodings):\n",
    "        self.input_encodings = input_encodings\n",
    "        self.target_encodings = target_encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.input_encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.target_encodings['input_ids'][idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T06:52:23.307967Z",
     "iopub.status.busy": "2024-05-30T06:52:23.307038Z",
     "iopub.status.idle": "2024-05-30T06:52:23.311872Z",
     "shell.execute_reply": "2024-05-30T06:52:23.311008Z",
     "shell.execute_reply.started": "2024-05-30T06:52:23.307933Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "dataset = ChemicalDataset(input_encodings, target_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T06:52:26.207863Z",
     "iopub.status.busy": "2024-05-30T06:52:26.207520Z",
     "iopub.status.idle": "2024-05-30T06:52:26.250784Z",
     "shell.execute_reply": "2024-05-30T06:52:26.249841Z",
     "shell.execute_reply.started": "2024-05-30T06:52:26.207838Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the dataset into train and eval sets\n",
    "train_size = int(0.9 * len(dataset))\n",
    "eval_size = len(dataset) - train_size\n",
    "train_dataset, eval_dataset = torch.utils.data.random_split(dataset, [train_size, eval_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T06:52:27.759129Z",
     "iopub.status.busy": "2024-05-30T06:52:27.758523Z",
     "iopub.status.idle": "2024-05-30T06:52:37.550515Z",
     "shell.execute_reply": "2024-05-30T06:52:37.549397Z",
     "shell.execute_reply.started": "2024-05-30T06:52:27.759100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06b2c4f930224ec4aafd970a835f2704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.02G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T06:52:38.106908Z",
     "iopub.status.busy": "2024-05-30T06:52:38.106588Z",
     "iopub.status.idle": "2024-05-30T06:52:39.914853Z",
     "shell.execute_reply": "2024-05-30T06:52:39.914112Z",
     "shell.execute_reply.started": "2024-05-30T06:52:38.106884Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    evaluation_strategy='epoch',  # Evaluate after \n",
    "    save_strategy='no',  # Save the model after each epoch\n",
    ")\n",
    "\n",
    "# Initialize the trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T06:52:53.191688Z",
     "iopub.status.busy": "2024-05-30T06:52:53.191285Z",
     "iopub.status.idle": "2024-05-30T08:38:32.779459Z",
     "shell.execute_reply": "2024-05-30T08:38:32.778493Z",
     "shell.execute_reply.started": "2024-05-30T06:52:53.191659Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20240530_065303-92dex5p6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/balalajka/huggingface/runs/92dex5p6' target=\"_blank\">stellar-snowflake-12</a></strong> to <a href='https://wandb.ai/balalajka/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/balalajka/huggingface' target=\"_blank\">https://wandb.ai/balalajka/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/balalajka/huggingface/runs/92dex5p6' target=\"_blank\">https://wandb.ai/balalajka/huggingface/runs/92dex5p6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4377' max='4377' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4377/4377 1:45:07, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.123200</td>\n",
       "      <td>0.081275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.060400</td>\n",
       "      <td>0.053579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.040900</td>\n",
       "      <td>0.045879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4377, training_loss=0.387703737167836, metrics={'train_runtime': 6339.1657, 'train_samples_per_second': 11.043, 'train_steps_per_second': 0.69, 'total_flos': 2.207472216109056e+16, 'train_loss': 0.387703737167836, 'epoch': 3.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model key: XXccc9411173297dda42dcf9cce4729ca98bc402\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T08:38:45.448692Z",
     "iopub.status.busy": "2024-05-30T08:38:45.448047Z",
     "iopub.status.idle": "2024-05-30T08:39:50.442043Z",
     "shell.execute_reply": "2024-05-30T08:39:50.441096Z",
     "shell.execute_reply.started": "2024-05-30T08:38:45.448649Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 01:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 0.045879025012254715, 'eval_runtime': 64.9847, 'eval_samples_per_second': 39.902, 'eval_steps_per_second': 0.631, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation results: {eval_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T09:55:33.197865Z",
     "iopub.status.busy": "2024-05-30T09:55:33.196949Z",
     "iopub.status.idle": "2024-05-30T09:55:33.204654Z",
     "shell.execute_reply": "2024-05-30T09:55:33.203464Z",
     "shell.execute_reply.started": "2024-05-30T09:55:33.197829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T08:44:02.462285Z",
     "iopub.status.busy": "2024-05-30T08:44:02.461490Z",
     "iopub.status.idle": "2024-05-30T08:44:02.502537Z",
     "shell.execute_reply": "2024-05-30T08:44:02.501683Z",
     "shell.execute_reply.started": "2024-05-30T08:44:02.462254Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load your data\n",
    "import pandas as pd\n",
    "data_to_test = pd.read_csv('/kaggle/input/data-train/product_smiles_test.csv', header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T08:44:05.006003Z",
     "iopub.status.busy": "2024-05-30T08:44:05.005320Z",
     "iopub.status.idle": "2024-05-30T08:44:05.012247Z",
     "shell.execute_reply": "2024-05-30T08:44:05.011206Z",
     "shell.execute_reply.started": "2024-05-30T08:44:05.005972Z"
    }
   },
   "outputs": [],
   "source": [
    "subset_data_1 = data_to_test.iloc[0:2000]\n",
    "subset_data_2 = data_to_test.iloc[2001:4000]\n",
    "subset_data_3 = data_to_test.iloc[4001:6000]\n",
    "subset_data_4 = data_to_test.iloc[6001:7690]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T10:33:43.234858Z",
     "iopub.status.busy": "2024-05-30T10:33:43.234186Z",
     "iopub.status.idle": "2024-05-30T10:33:43.239988Z",
     "shell.execute_reply": "2024-05-30T10:33:43.238904Z",
     "shell.execute_reply.started": "2024-05-30T10:33:43.234825Z"
    }
   },
   "outputs": [],
   "source": [
    "data_to_test = subset_data_4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T10:33:49.320869Z",
     "iopub.status.busy": "2024-05-30T10:33:49.320014Z",
     "iopub.status.idle": "2024-05-30T10:33:49.327584Z",
     "shell.execute_reply": "2024-05-30T10:33:49.326471Z",
     "shell.execute_reply.started": "2024-05-30T10:33:49.320835Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1689"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T11:25:17.063600Z",
     "iopub.status.busy": "2024-05-30T11:25:17.062778Z",
     "iopub.status.idle": "2024-05-30T11:25:17.074327Z",
     "shell.execute_reply": "2024-05-30T11:25:17.073275Z",
     "shell.execute_reply.started": "2024-05-30T11:25:17.063568Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6001</th>\n",
       "      <td>CC(C)(C)[Si](C)(C)OCCC(CO[Si](C)(C)C(C)(C)C)OS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6002</th>\n",
       "      <td>CCOC(=O)C(C)(C)N1CCC(NCc2ccc(-c3ccc(C(F)(F)F)c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6003</th>\n",
       "      <td>CC(C)(C)CC1NC(C(=O)Nc2ccc3c(c2)C(=O)NC3=O)C(c2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6004</th>\n",
       "      <td>Cc1ccc(NC(=O)c2ccc(CN3CCOCC3)c(Br)c2)cc1Nc1ncc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6005</th>\n",
       "      <td>O=C(NCc1ccc(F)c(F)c1)C(COC(F)F)N(Cc1ccccc1)Cc1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0\n",
       "6001  CC(C)(C)[Si](C)(C)OCCC(CO[Si](C)(C)C(C)(C)C)OS...\n",
       "6002  CCOC(=O)C(C)(C)N1CCC(NCc2ccc(-c3ccc(C(F)(F)F)c...\n",
       "6003  CC(C)(C)CC1NC(C(=O)Nc2ccc3c(c2)C(=O)NC3=O)C(c2...\n",
       "6004  Cc1ccc(NC(=O)c2ccc(CN3CCOCC3)c(Br)c2)cc1Nc1ncc...\n",
       "6005  O=C(NCc1ccc(F)c(F)c1)C(COC(F)F)N(Cc1ccccc1)Cc1..."
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T10:33:56.543693Z",
     "iopub.status.busy": "2024-05-30T10:33:56.543278Z",
     "iopub.status.idle": "2024-05-30T11:00:31.961763Z",
     "shell.execute_reply": "2024-05-30T11:00:31.960625Z",
     "shell.execute_reply.started": "2024-05-30T10:33:56.543663Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Products: 100%|██████████| 1689/1689 [26:35<00:00,  1.06it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def predict_with_beam_search(model, tokenizer, product, num_beams=25, max_length=2048):\n",
    "    \"\"\"\n",
    "    Generates predictions for a given product using beam search.\n",
    "\n",
    "    Args:\n",
    "        model: The trained model for generation.\n",
    "        tokenizer: The tokenizer used for processing text.\n",
    "        product: The product SMILES string for which to predict reactants.\n",
    "        num_beams: Number of beams to use in beam search (default: 25).\n",
    "        max_length: Maximum length of the generated sequence (default: 2048).\n",
    "\n",
    "    Returns:\n",
    "        A list of predicted reactant SMILES strings (one for each beam).\n",
    "    \"\"\"\n",
    "    product_encoding = tokenizer(product, truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
    "    product_encoding = {k: v.to(model.device) for k, v in product_encoding.items()}\n",
    "\n",
    "    # Generate predictions using beam search\n",
    "    beam_outputs = model.generate(\n",
    "        **product_encoding,\n",
    "        num_beams=num_beams,\n",
    "        early_stopping=True,\n",
    "        max_length=max_length\n",
    "    )\n",
    "\n",
    "    # Decode beam outputs and return as list\n",
    "    predicted_reactants = [tokenizer.decode(out, skip_special_tokens=True) for out in beam_outputs]\n",
    "    return predicted_reactants\n",
    "\n",
    "# Create an empty list to store predicted reactants\n",
    "predicted_reactants_list = []\n",
    "\n",
    "# Progress bar with tqdm\n",
    "with tqdm(total=len(data_to_test[0]), desc=\"Processing Products\") as progress_bar:\n",
    "    for product in data_to_test[0]:\n",
    "        # Generate predictions using beam search function\n",
    "        predicted_reactants = predict_with_beam_search(model, tokenizer, product)\n",
    "        predicted_reactants_list.append(predicted_reactants)  # List of predictions for each product\n",
    "\n",
    "        # Update progress bar after each iteration\n",
    "        progress_bar.update(1)\n",
    "\n",
    "# Create a pandas DataFrame from the predicted reactants\n",
    "output_df = pd.DataFrame({\n",
    "    'product': data_to_test[0].tolist(),  # Assuming data_to_test[0] contains product SMILES\n",
    "    'predicted_reactants': predicted_reactants_list  # List of lists (one inner list per product)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T11:05:18.865068Z",
     "iopub.status.busy": "2024-05-30T11:05:18.864365Z",
     "iopub.status.idle": "2024-05-30T11:05:18.880341Z",
     "shell.execute_reply": "2024-05-30T11:05:18.878744Z",
     "shell.execute_reply.started": "2024-05-30T11:05:18.865033Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [C[Si](C)(C)OC[C@H](CCCO)[C@@H](C)C.CS(=O)(=O)Cl]\n",
       "1    [CCOC(=O)C(C)(C)N1CCC(N)CC1.O=Cc1ccc(-c2ccc(C(...\n",
       "2    [CC(C)(C)CC1NC(C(=O)O)C(c2cccc(Cl)c2F)C1(C#N)c...\n",
       "3    [C1COCCN1.Cc1ccc(Nc2nccc(-c3cccnc3)n2)cc1Nc1nc...\n",
       "4             [Nc1ccc(CNC(=O)C(COC(F)F)Cc2ccccc2)cc1F]\n",
       "5    [CC(C)(C)[C@@H](CO)Nc1cc(-c2n[nH]c3cc(F)cnc3c2...\n",
       "6    [Cc1c(SCC2CCN(C(=O)Cc3ccc(Cl)nc3)CC2)ccc2c1COC...\n",
       "7    [C=CC(=O)Nc1cccc(-c2cccc3cnc(Nc4ccc(Br)cc4)nc2...\n",
       "8    [O=C(Nc1ccc(F)cc1)[C@H]1C[C@@H](Cc2ccccc2F)CN1...\n",
       "9             [BrCc1ccc(C(F)(F)F)cc1.COC(=O)c1ncccc1N]\n",
       "Name: predicted_reactants, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = output_df[\"predicted_reactants\"]\n",
    "output.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T11:05:22.654123Z",
     "iopub.status.busy": "2024-05-30T11:05:22.653765Z",
     "iopub.status.idle": "2024-05-30T11:05:22.665367Z",
     "shell.execute_reply": "2024-05-30T11:05:22.661320Z",
     "shell.execute_reply.started": "2024-05-30T11:05:22.654096Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1689"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T11:05:34.097013Z",
     "iopub.status.busy": "2024-05-30T11:05:34.096270Z",
     "iopub.status.idle": "2024-05-30T11:05:34.121736Z",
     "shell.execute_reply": "2024-05-30T11:05:34.120664Z",
     "shell.execute_reply.started": "2024-05-30T11:05:34.096979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to 'predicted_reactants.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save the DataFrame as a CSV file\n",
    "output_df.to_csv('predicted_reactants_fourth.csv', index=False)  # Adjust filename as needed\n",
    "\n",
    "print(f\"Predictions saved to 'predicted_reactants.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5100002,
     "sourceId": 8537815,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5106953,
     "sourceId": 8547245,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5110220,
     "sourceId": 8551604,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
